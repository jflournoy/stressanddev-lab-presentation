---
title: "Hello, Stress & Development Lab!"
author: "John Flournoy"
date: "1/11/2018"
output: 
  ioslides_presentation:
    incremental: true
    widescreen: true
    mathjax: local
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE, message = FALSE)
inv_logit <- function(x){
    exp(x)/(1+exp(x))
}
```


## A big question, and approach {.build}

Why do we observe increases in negative health risk during adolescence?

Can we gain insight into the causes of adolescent risk-taking ...

... if we understand individual differences in thought and behavior as _strategies_ for satisfying fundamental motivations?

## Methodological approaches

- Modeling development (adolescence, adulthood)
    - Models encode hypotheses
        - Networks versus latent variables ([Network model of personality](https://figshare.com/articles/A_Network_Approach_to_Characterizing_Personality_in_the_Life_and_Time_Longitudinal_Sample/1447279/2))
        - Distinguishing sources of variance ([RI-CLPM](https://jflournoy.github.io/2017/10/20/riclpm-lavaan-demo/), LCM-SR)
- Modeling behavior
    - Increase reliability of individual differences in behavior (Yellow Light Game)
    - Allow measurement of latent process (Social Probabilistic Learning Task)

# Adolescent risk taking {.build}

The big question: Why do negative health outcomes increase in adolescence?

## Negative health outcomes and health risking behavior

<img src='https://gitlab.com/jflournoy/Adolescent_Injury_Risk/raw/master/unintentional_injury_data_by_sex.png' width = 60% style='float:right' />

- Increases in unintentional injury
- ... alcohol and drug abuse (Hooshmand, Willoughby, & Good, 2012)
- ... risky sexual behavior (Stevenson, Zimmerman, & Caldwell, 2007)

## Changes in risk and reward processing

Explanations focus on 

- Reward sensitivity during risky choices (e.g., Casey, 2015)
- ... in peer contexts (e.g., Peake et al., 2013, Silva et al., 2016).

# The Yellow Light Game {.build}

Characterizing a laboratory paradigm commonly used to investigate risk decisions.

## The Stoplight Game

The Stoplight Game (Steinberg et al, 2008) has been used in dozens of experiments as a measure of risk-taking 

- Small correlations with self report sensation seeking (r=.2; Harden et al., 2017; Steinberg et al. 2008)
- Game-elicited neural response correlates with convergent measures (Kahn et al., 2014)
- However, some aspects of this task remain unclear
    - Making a risky choice also increases task performance (stop = -3s, EV of go = -1.8s)
    - Most variance is not shared with convergent measures (Harden et al, 2017)

## The psychometric properties of Stoplight

[Harden et al. 2017](https://doi.org/10.1016/j.dcn.2016.12.007): 398 twins, 4 factors capture variance of a wide range of cognitive control and incentive processing tasks 

- Reward-seeking factor loadings (A = .66, E = .34)

        Stoplight: intersections  0.32
        IGT: Good decks           0.56
        IGT: Bad decks            0.22
        Delay Discounting         0.15
        BART: Avg. adjusted pumps 0.47	
        Sensation seeking         0.16
- Stoplight *unique* variance: 78% is non-shared env + measurement error
- A lot of unaccounted for variance

## Aims of the Yellow Light Game study

1. Increase precision of task design
2. Improve task characterization of risk taking

## Aim 1: Task design improvements

[The Yellow Light Game](https://dsn.uoregon.edu/research/yellow-light-game/) software is customization. 

In the configuration for this study:

- We can distinguish propensity to choose risk option, and learning
- Performance insensitive to overall proportion of risk choice
- But one can learn to increase performance

## YLG Task & Protocol description

<img src = 'stoplight.jpg' style = 'width: 50%; float: right' />

Driving simulation

- Each intersection has 1 of 3 risk levels 
- Risk levels correspond to different yellow light onsets
    - 4 "early" P(crash) = .75
    - 4 "late" P(crash) = .25
    - 12 "middle" P(crash) = .5
- 8 runs, 20 intersections per run
- Run 5 and 6 (**peer**): watched by two "peers" via remote desktop after cyberball inclusion
- Run 7 and 8 (**excl**): watched after being excluded in cyberball

## The data to model

N = 174, 84 boys (Age M = 14.3 [11-17]) 

<img src = 'https://jflournoy.github.io/ylglearning/articles/ylg_descriptives_and_diagnostics_files/figure-html/rawpropplot-1.png' style = 'width: 70%;' />

All analyses available in R package: [`ylglearning`](https://jflournoy.github.io/ylglearning/)

## Aim 2: Improve task characterization of risk taking

- $a$. Can we mprove amount of between-person proportion of variance?
- $b$. Can we distinguish risk-taking from learning?
    - ... and are there differences across peer conditions?
- $c$. Does a better model improve correlations with a convergent measure?

## 2a. Improve between-person variance {.build}

Proportion of "Go" decisions is the most common summary used.

Intercept-only multi-level logistic regression is basically equivalent to this.

ICC<sub>pGo</sub> = [0.12](https://jflournoy.github.io/ylglearning/articles/ylg_descriptives_and_diagnostics.html#task-reliability)

This could be one explanation for the somewhat small correlations in the literature.

## 2a. Diagnosing this low ICC

Is a simple Bernoulli process not appropriate? Structure of task behavior may be more complex.  

- Participants tend not to make the same decision twice <img src = 'https://jflournoy.github.io/ylglearning/articles/ylg_descriptives_and_diagnostics_files/figure-html/autocorrelationvisualization-1.png' style = 'width:50%; float:right' />
- "Last decision was 'Go'?" parameter increases ICC from **.12 to .32**
- But now we have two variables to interpret!

## 2a. Reward-learning?

- [Reward-learning model](https://jflournoy.shinyapps.io/rw_model/) (left) is not better than logistic regression (right) <div style = 'float:right;width:100%'><img src = 'https://jflournoy.github.io/ylglearning/articles/ylg_expanding_the_logistic_model_files/figure-html/unnamed-chunk-6-1.png' style = 'width: 50%' /><img src = 'https://jflournoy.github.io/ylglearning/articles/ylg_expanding_the_logistic_model_files/figure-html/brmIxTypeppcheck-1.png' style = 'width: 50%' /></div>

## 2a. Conclusion

Yes, accounting for more complicated task-behavior structure improves reliability (with a possible loss of interpretability). 

## 2b. Distinguish learning and risk tolerance

<img src = 'https://jflournoy.github.io/ylglearning/articles/ylg_questionnaire_analyses_files/figure-html/plotfittedpreds-1.png' style = 'width: 95%' />

## 2b. Conclusion {.build}

There are some differences in behavior between "learnable" intersections that might indicate learning.

Evidence for risk-taking increases for the "middle" (non-learnable) intersections.

**Task behavior is more complex than we may have appreciated.**

## 2c. Improve correlations with a convergent measure

Reliability is a precondition for correlation
- In this model, [63%](https://jflournoy.github.io/ylglearning/articles/ylg_questionnaire_analyses.html) of the variance is between-person.

Assess improvement by comparing parameters during _Alone_ condition
    - Simple proportions model: P(Go)
    - Full model: P(Go|stop)<sub>M</sub>, P(Go|Go)<sub>M</sub>
    - Self-report sensation seeking from the UPPS-P (Cyders et al., 2007; Whiteside & Lynam, 2001).

## 2c. Intercorrelatoins 

<span style = 'font-size: .6em'>(Probabilities transformed with normal quantile function)</span>

|    | 1. Sensation Seeking    | 2. P(Go)  | 3. P(Go\|Stop)| 4. P(Go\|Go)  | 5. Age    |
|---:|---------:|----------:|--------------:|--------------:|----------:|
| **2. P(Go)**       |  <span style='font-size:1.2em;font-style:bold'>0.13</span>    |  |  |  |  |
| **3. P(Go\|Stop)** |  <span style='font-size:1.2em;font-style:bold'>0.17</span>    |   0.91    |  |  |  |
| 4.P(Go\|Go)        |  0.08     |   0.79    |     0.57      |  |  |
| 5. Age             | -0.05     |  -0.02    |    -0.07      |  0.06         |  |
| 6. Sex             | -0.11     |  -0.07    |    -0.07      |  0.01         |   0.20    |

- P(Go|Stop) > P(Go) (_ns_, t = -1.12, p < .26)
- Regressions controlling for age and sex much the same 

## 2c. Implications for power

_r_<sub>SS.P(Go)</sub> = .13 [-.01, .28]

_r_<sub>SS.P(Go|Stop)</sub> = .17 [.02, .31]

|                   | _r_<sub>SS.P(Go)</sub>    | _r_<sub>SS.P(Go\|Stop)</sub>  | Difference    |
|               ----|                       ---:|                           ---:|           ---:|
|   Obsv Power      |           42%             |           61%                 |   20%         |
| N (Power = 80%)   |           428             |           265                 |   163 (62%)   |


## Conclusions

- More fine-grained task modeling improves correlations with convergent measures.
    - This implies that the task is measuring more than just risk
    - But also adds support for being able to generalize the part that _is_ about risk-taking
- Potentially some differences on average in learning motivation _and_ risk-taking in different peer experiences
    - Possibly modulated by individual differences
    - Which we can now more precisely assess!
    - But why? To what end?

# Thank you!

For the opportunity to share this talk with you...

# This slide intentionally left blank
